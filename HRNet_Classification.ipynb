{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-21T16:31:13.854765Z","iopub.execute_input":"2023-02-21T16:31:13.855797Z","iopub.status.idle":"2023-02-21T16:31:15.127071Z","shell.execute_reply.started":"2023-02-21T16:31:13.855677Z","shell.execute_reply":"2023-02-21T16:31:15.125660Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nTue Feb 21 16:31:14 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   48C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nimport tensorflow as tf\nimport keras\nimport keras.backend as K\nfrom keras.layers import Conv2D, BatchNormalization, Activation, Dense, Input, Add, GlobalAveragePooling2D, UpSampling2D, Concatenate\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-02-21T16:31:15.132822Z","iopub.execute_input":"2023-02-21T16:31:15.135804Z","iopub.status.idle":"2023-02-21T16:31:23.136426Z","shell.execute_reply.started":"2023-02-21T16:31:15.135748Z","shell.execute_reply":"2023-02-21T16:31:23.135335Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)       \nprint(keras.__version__)    ","metadata":{"execution":{"iopub.status.busy":"2023-02-21T16:31:23.138214Z","iopub.execute_input":"2023-02-21T16:31:23.139170Z","iopub.status.idle":"2023-02-21T16:31:23.144971Z","shell.execute_reply.started":"2023-02-21T16:31:23.139132Z","shell.execute_reply":"2023-02-21T16:31:23.143775Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2.9.2\n2.9.0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1/255.0,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   brightness_range = (0.1, 0.25),\n                                   rotation_range = 20,\n                                   vertical_flip = True,\n                                   horizontal_flip = True,\n                                   validation_split = 0.2)\n \n# test_datagen =  ImageDataGenerator(rescale = 1/255.0,\n#                                    shear_range = 0.2,\n#                                    zoom_range = 0.2,\n#                                    brightness_range = (0.1, 0.25),\n#                                    rotation_range = 20,\n#                                    vertical_flip = True,\n#                                    horizontal_flip = True,)\n    \n    \ntraining_set = train_datagen.flow_from_directory('/kaggle/input/imagenet11/ImageNet-13 Original Image Dateset/image',\n                                                 target_size = (224, 224),\n                                                 batch_size = 16,\n                                                 class_mode = 'categorical',\n                                                 subset = 'training')\n\nvalid_set = train_datagen.flow_from_directory('/kaggle/input/imagenet11/ImageNet-13 Original Image Dateset/image',\n                                            target_size = (224, 224),\n                                            batch_size = 16,\n                                            class_mode = 'categorical',\n                                            subset = 'validation'\n                                            )\n\n# test_set = test_datagen.flow_from_directory('/kaggle/input/dogs-cats-images/dataset/test_set/',\n#                                             target_size = (256, 256),\n#                                             batch_size = 16,\n#                                             class_mode = 'categorical',)","metadata":{"execution":{"iopub.status.busy":"2023-02-21T16:34:22.620749Z","iopub.execute_input":"2023-02-21T16:34:22.621147Z","iopub.status.idle":"2023-02-21T16:34:26.211389Z","shell.execute_reply.started":"2023-02-21T16:34:22.621111Z","shell.execute_reply":"2023-02-21T16:34:26.210005Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found 13400 images belonging to 13 classes.\nFound 3350 images belonging to 13 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def Conv_Block(inputs, n_filters):\n\n  y = Conv2D(filters=n_filters, kernel_size=3, strides=1, padding='same', use_bias=False)(inputs)\n  y = BatchNormalization()(y)\n  y = Activation('relu')(y)\n\n  return y\n\ndef Strided_Conv_Block(inputs, n_filters, n_stride):\n\n  y = Conv2D(filters=n_filters, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n  y = BatchNormalization()(y)\n  y = Activation('relu')(y)\n\n  return y\n\ndef Multi_Resolution_Parallel_Convolution(inputs, n_filters):\n\n  y = Conv_Block(inputs, n_filters)\n  y = Conv_Block(y, n_filters)\n  y = Conv_Block(y, n_filters)\n  y = Conv_Block(y, n_filters)\n\n  return y\n\ndef Multi_Resolution_Fusion1(stage1_in, stage2_in, stage3_in, n_filters):\n\n  stage2_i = Strided_Conv_Block(stage1_in, 2*n_filters, n_stride=2)\n  stage2_ii = Strided_Conv_Block(stage2_i, 4*n_filters, n_stride=2)\n  stage3 = Concatenate()([stage3_in, stage2_ii])\n  stage3 = Conv2D(filters=4*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage3)\n  stage3 = BatchNormalization()(stage3)\n  stage3 = Activation('relu')(stage3)\n\n\n  stage2 = Concatenate()([stage2_in, stage2_i])\n  stage2 = Conv2D(filters=2*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage2)\n  stage2 = BatchNormalization()(stage2)\n  stage2 = Activation('relu')(stage2)\n\n\n  stage1_i = UpSampling2D(size=2, interpolation='bilinear')(stage2_in)\n  stage1 = Concatenate()([stage1_in, stage1_i])\n  stage1 = Conv2D(filters=n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage1)\n  stage1 = BatchNormalization()(stage1)\n  stage1 = Activation('relu')(stage1)\n\n  return stage1, stage2, stage3\n\ndef Multi_Resolution_Fusion2(stage1_in, stage2_in, stage3_in, stage4_in, n_filters):\n\n  stage4_i = Strided_Conv_Block(stage1_in, 2*n_filters, n_stride=2)\n  stage4_ii = Strided_Conv_Block(stage4_i, 4*n_filters, n_stride=2)\n  stage4_iii = Strided_Conv_Block(stage4_ii, 8*n_filters, n_stride=2)\n\n  stage4_iii_i = Strided_Conv_Block(stage2_in, 4*n_filters, n_stride=2)\n  stage4_iii_ii = Strided_Conv_Block(stage4_iii_i, 8*n_filters, n_stride=2)\n\n  stage4 = Concatenate()([stage4_in, stage4_iii, stage4_iii_ii])\n  stage4 = Conv2D(filters=8*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage4)\n  stage4 = BatchNormalization()(stage4)\n  stage4 = Activation('relu')(stage4)\n\n\n  stage3 = Concatenate()([stage3_in, stage4_ii, stage4_iii_i])\n  stage3 = Conv2D(filters=4*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage3)\n  stage3 = BatchNormalization()(stage3)\n  stage3 = Activation('relu')(stage3)\n\n\n  stage2_i = UpSampling2D(size=2, interpolation='bilinear')(stage3_in)\n  stage2 = Concatenate()([stage2_in, stage4_i, stage2_i])\n  stage2 = Conv2D(filters=2*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage2)\n  stage2 = BatchNormalization()(stage2)\n  stage2 = Activation('relu')(stage2)\n\n\n  stage1_i = UpSampling2D(size=2, interpolation='bilinear')(stage2_in)\n  stage1_ii = UpSampling2D(size=4, interpolation='bilinear')(stage3_in)\n  stage1 = Concatenate()([stage1_in, stage1_i, stage1_ii])\n  stage1 = Conv2D(filters=n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage1)\n  stage1 = BatchNormalization()(stage1)\n  stage1 = Activation('relu')(stage1)\n\n  return stage1, stage2, stage3, stage4\n\ndef Multi_Resolution_Fusion3(stage1_in, stage2_in, stage3_in, stage4_in, n_filters):\n\n  stage4_i = Strided_Conv_Block(stage1_in, 2*n_filters, n_stride=2)\n  stage4_ii = Strided_Conv_Block(stage4_i, 4*n_filters, n_stride=2)\n  stage4_iii = Strided_Conv_Block(stage4_ii, 8*n_filters, n_stride=2)\n\n  stage4_iii_i = Strided_Conv_Block(stage2_in, 4*n_filters, n_stride=2)\n  stage4_iii_ii = Strided_Conv_Block(stage4_iii_i, 8*n_filters, n_stride=2)\n\n  stage4_iii_ii_i = Strided_Conv_Block(stage3_in, 8*n_filters, n_stride=2)\n\n  stage4 = Concatenate()([stage4_in, stage4_iii, stage4_iii_ii, stage4_iii_ii_i])\n  stage4 = Conv2D(filters=8*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage4)\n  stage4 = BatchNormalization()(stage4)\n  stage4 = Activation('relu')(stage4)\n\n\n  stage3_i = UpSampling2D(size=2, interpolation='bilinear')(stage4_in)\n  stage3 = Concatenate()([stage3_in, stage4_ii, stage4_iii_i, stage3_i])\n  stage3 = Conv2D(filters=4*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage3)\n  stage3 = BatchNormalization()(stage3)\n  stage3 = Activation('relu')(stage3)\n\n\n  stage2_i = UpSampling2D(size=2, interpolation='bilinear')(stage3_in)\n  stage2_ii = UpSampling2D(size=4, interpolation='bilinear')(stage4_in)\n  stage2 = Concatenate()([stage2_in, stage4_i, stage2_i, stage2_ii])\n  stage2 = Conv2D(filters=2*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage2)\n  stage2 = BatchNormalization()(stage2)\n  stage2 = Activation('relu')(stage2)\n\n\n  stage1_i = UpSampling2D(size=2, interpolation='bilinear')(stage2_in)\n  stage1_ii = UpSampling2D(size=4, interpolation='bilinear')(stage3_in)\n  stage1_iii = UpSampling2D(size=8, interpolation='bilinear')(stage4_in)\n  stage1 = Concatenate()([stage1_in, stage1_i, stage1_ii, stage1_iii])\n  stage1 = Conv2D(filters=n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage1)\n  stage1 = BatchNormalization()(stage1)\n  stage1 = Activation('relu')(stage1)\n\n  return stage1, stage2, stage3, stage4\n\ndef HRNet(inputs, n_filters):\n\n  # inputs = Input(input_shape)\n\n  stage1 = Multi_Resolution_Parallel_Convolution(inputs, n_filters)\n  stage2 = Strided_Conv_Block(stage1, 2*n_filters, n_stride=2)\n\n  stage1 = Conv_Block(stage1, n_filters)\n  stage1 = Multi_Resolution_Parallel_Convolution(stage1, n_filters) \n  stage2 = Multi_Resolution_Parallel_Convolution(stage2, 2*n_filters)\n  stage3 = Strided_Conv_Block(stage2, 4*n_filters, n_stride=2)\n\n  stage1, stage2, stage3 = Multi_Resolution_Fusion1(stage1, stage2, stage3, n_filters)\n  stage1 = Multi_Resolution_Parallel_Convolution(stage1, n_filters)\n  stage2 = Multi_Resolution_Parallel_Convolution(stage2, 2*n_filters)\n  stage3 = Multi_Resolution_Parallel_Convolution(stage3, 4*n_filters)\n  stage4 = Strided_Conv_Block(stage3, 8*n_filters, n_stride=2)\n\n  stage1, stage2, stage3, stage4 = Multi_Resolution_Fusion2(stage1, stage2, stage3, stage4, n_filters)\n  stage1 = Multi_Resolution_Parallel_Convolution(stage1, n_filters)\n  stage2 = Multi_Resolution_Parallel_Convolution(stage2, 2*n_filters)\n  stage3 = Multi_Resolution_Parallel_Convolution(stage3, 4*n_filters)\n  stage4 = Multi_Resolution_Parallel_Convolution(stage4, 8*n_filters)\n  stage1, stage2, stage3, stage4 = Multi_Resolution_Fusion3(stage1, stage2, stage3, stage4, n_filters)\n  # print(stage1.shape, stage2.shape, stage3.shape, stage4.shape)\n  \n  return stage1, stage2, stage3, stage4\n\ndef HRNet_Classification(input_shape, n_classes, n_filters):\n\n  inputs = Input(input_shape)\n\n  stage1, stage2, stage3, stage4 = HRNet(inputs, n_filters=n_filters)\n\n  stage1 = Conv2D(filters=4*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage1)\n  stage1 = BatchNormalization()(stage1)\n  stage1 = Activation('relu')(stage1)\n\n  stage2 = Conv2D(filters=8*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage2)\n  stage2 = BatchNormalization()(stage2)\n  stage2 = Activation('relu')(stage2)\n\n  stage3 = Conv2D(filters=16*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage3)\n  stage3 = BatchNormalization()(stage3)\n  stage3 = Activation('relu')(stage3)\n\n  stage4 = Conv2D(filters=32*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(stage4)\n  stage4 = BatchNormalization()(stage4)\n  stage4 = Activation('relu')(stage4)\n\n  y1 = Strided_Conv_Block(stage1, 8*n_filters, n_stride=2)\n  y = Add()([stage2, y1])\n\n  y2 = Strided_Conv_Block(y1, 16*n_filters, n_stride=2)\n  y = Add()([stage3, y2])\n\n  y3 = Strided_Conv_Block(y2, 32*n_filters, n_stride=2)\n  y = Add()([stage4, y3])\n\n  y = Conv2D(filters=64*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(y)\n  y = BatchNormalization()(y)\n  y = Activation('relu')(y)\n\n  y = Conv2D(filters=64*n_filters, kernel_size=1, strides=1, padding='same', use_bias=False)(y)\n  y = BatchNormalization()(y)\n  y = Activation('relu')(y)\n\n  y = GlobalAveragePooling2D()(y)\n  y = Dense(n_classes, use_bias=False)(y)\n\n  if n_classes == 1:\n    y = Activation('sigmoid')(y)\n  else:\n    y = Activation('softmax')(y)\n  # print(y.shape)\n\n  model = Model(inputs=inputs, outputs=y)\n\n  return model\n\n\nmodel = HRNet_Classification(input_shape=(224,224,3), n_classes=13, n_filters=16)\n# model.summary()  ","metadata":{"execution":{"iopub.status.busy":"2023-02-21T16:35:33.656801Z","iopub.execute_input":"2023-02-21T16:35:33.657232Z","iopub.status.idle":"2023-02-21T16:35:35.025770Z","shell.execute_reply.started":"2023-02-21T16:35:33.657166Z","shell.execute_reply":"2023-02-21T16:35:35.024768Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\"\"\" callbacks \"\"\"\ncheckpoint_filepath = './HRNet_{epoch}.h5'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=False,\n    # monitor='val_iou_score',\n    # mode='max',\n    verbose = 1,\n    period = 3,\n    save_best_only=False)\n\ncsv_path = \"./SQNet.csv\"\ncallbacks = [\n    model_checkpoint_callback,\n    ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.5, verbose=1),\n    CSVLogger(csv_path),\n    EarlyStopping(monitor=\"val_loss\", patience=12)]","metadata":{"execution":{"iopub.status.busy":"2023-02-21T16:35:35.028114Z","iopub.execute_input":"2023-02-21T16:35:35.028742Z","iopub.status.idle":"2023-02-21T16:35:35.038273Z","shell.execute_reply.started":"2023-02-21T16:35:35.028704Z","shell.execute_reply":"2023-02-21T16:35:35.036953Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss=tf.keras.losses.CategoricalCrossentropy(),    #label_smoothing=0.1),\n    optimizer=tf.keras.optimizers.Adam(0.01),\n    metrics=['accuracy'])\n\nh1 = model.fit(\n  training_set,\n  validation_data=valid_set,\n  batch_size=16,\n  epochs=1000,\n  steps_per_epoch=len(training_set)//10,\n  workers=-1,\n  use_multiprocessing=True,\n  validation_steps=len(valid_set)//10,\n  callbacks=callbacks)\n\nmodel.save('./HRNet_last.h5')","metadata":{"execution":{"iopub.status.busy":"2023-02-21T17:21:25.850517Z","iopub.execute_input":"2023-02-21T17:21:25.850916Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n83/83 [==============================] - ETA: 0s - loss: 2.2269 - accuracy: 0.2319\nEpoch 1: saving model to ./HRNet_1.h5\n83/83 [==============================] - 189s 2s/step - loss: 2.2269 - accuracy: 0.2319 - val_loss: 111.3967 - val_accuracy: 0.0881 - lr: 0.0100\nEpoch 2/1000\n83/83 [==============================] - 174s 2s/step - loss: 2.1327 - accuracy: 0.2644 - val_loss: 2.9857 - val_accuracy: 0.1570 - lr: 0.0100\nEpoch 3/1000\n83/83 [==============================] - 174s 2s/step - loss: 2.1140 - accuracy: 0.2643 - val_loss: 50.5115 - val_accuracy: 0.0872 - lr: 0.0100\nEpoch 4/1000\n83/83 [==============================] - ETA: 0s - loss: 2.1250 - accuracy: 0.2718\nEpoch 4: saving model to ./HRNet_4.h5\n83/83 [==============================] - 176s 2s/step - loss: 2.1250 - accuracy: 0.2718 - val_loss: 93.2836 - val_accuracy: 0.0872 - lr: 0.0100\nEpoch 5/1000\n83/83 [==============================] - 175s 2s/step - loss: 2.1040 - accuracy: 0.2620 - val_loss: 42.4750 - val_accuracy: 0.0913 - lr: 0.0100\nEpoch 6/1000\n83/83 [==============================] - 176s 2s/step - loss: 2.1219 - accuracy: 0.2718 - val_loss: 15.2565 - val_accuracy: 0.0875 - lr: 0.0100\nEpoch 7/1000\n83/83 [==============================] - ETA: 0s - loss: 2.1132 - accuracy: 0.2914\nEpoch 7: saving model to ./HRNet_7.h5\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n83/83 [==============================] - 176s 2s/step - loss: 2.1132 - accuracy: 0.2914 - val_loss: 6.8968 - val_accuracy: 0.1006 - lr: 0.0100\nEpoch 8/1000\n83/83 [==============================] - 175s 2s/step - loss: 2.0225 - accuracy: 0.2907 - val_loss: 2.2282 - val_accuracy: 0.2776 - lr: 0.0050\nEpoch 9/1000\n83/83 [==============================] - 175s 2s/step - loss: 2.0053 - accuracy: 0.3005 - val_loss: 3.2963 - val_accuracy: 0.1573 - lr: 0.0050\nEpoch 10/1000\n83/83 [==============================] - ETA: 0s - loss: 2.0185 - accuracy: 0.2989\nEpoch 10: saving model to ./HRNet_10.h5\n83/83 [==============================] - 175s 2s/step - loss: 2.0185 - accuracy: 0.2989 - val_loss: 2.7865 - val_accuracy: 0.1403 - lr: 0.0050\nEpoch 11/1000\n83/83 [==============================] - 173s 2s/step - loss: 2.0157 - accuracy: 0.2989 - val_loss: 1.9897 - val_accuracy: 0.3087 - lr: 0.0050\nEpoch 12/1000\n83/83 [==============================] - 173s 2s/step - loss: 1.9548 - accuracy: 0.3321 - val_loss: 2.9205 - val_accuracy: 0.1704 - lr: 0.0050\nEpoch 13/1000\n83/83 [==============================] - ETA: 0s - loss: 1.9886 - accuracy: 0.3110\nEpoch 13: saving model to ./HRNet_13.h5\n83/83 [==============================] - 180s 2s/step - loss: 1.9886 - accuracy: 0.3110 - val_loss: 4.5370 - val_accuracy: 0.1809 - lr: 0.0050\nEpoch 14/1000\n83/83 [==============================] - 178s 2s/step - loss: 1.9977 - accuracy: 0.3072 - val_loss: 3.0904 - val_accuracy: 0.2000 - lr: 0.0050\nEpoch 15/1000\n83/83 [==============================] - 173s 2s/step - loss: 1.9565 - accuracy: 0.3298 - val_loss: 3.1660 - val_accuracy: 0.1854 - lr: 0.0050\nEpoch 16/1000\n83/83 [==============================] - ETA: 0s - loss: 1.9065 - accuracy: 0.3434\nEpoch 16: saving model to ./HRNet_16.h5\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n83/83 [==============================] - 174s 2s/step - loss: 1.9065 - accuracy: 0.3434 - val_loss: 4.2788 - val_accuracy: 0.2051 - lr: 0.0050\nEpoch 17/1000\n83/83 [==============================] - 176s 2s/step - loss: 1.8856 - accuracy: 0.3321 - val_loss: 2.2264 - val_accuracy: 0.2681 - lr: 0.0025\nEpoch 18/1000\n83/83 [==============================] - 174s 2s/step - loss: 1.9119 - accuracy: 0.3313 - val_loss: 1.8244 - val_accuracy: 0.3645 - lr: 0.0025\nEpoch 19/1000\n83/83 [==============================] - ETA: 0s - loss: 1.8792 - accuracy: 0.3502\nEpoch 19: saving model to ./HRNet_19.h5\n83/83 [==============================] - 173s 2s/step - loss: 1.8792 - accuracy: 0.3502 - val_loss: 1.9823 - val_accuracy: 0.3263 - lr: 0.0025\nEpoch 20/1000\n83/83 [==============================] - 175s 2s/step - loss: 1.8660 - accuracy: 0.3636 - val_loss: 2.0182 - val_accuracy: 0.3075 - lr: 0.0025\nEpoch 21/1000\n83/83 [==============================] - 174s 2s/step - loss: 1.8188 - accuracy: 0.3795 - val_loss: 1.8608 - val_accuracy: 0.3487 - lr: 0.0025\nEpoch 22/1000\n37/83 [============>.................] - ETA: 45s - loss: 1.8092 - accuracy: 0.3480","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate_generator(test_set, steps=64, workers=-1, use_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-21T17:21:21.710547Z","iopub.status.idle":"2023-02-21T17:21:21.711016Z","shell.execute_reply.started":"2023-02-21T17:21:21.710757Z","shell.execute_reply":"2023-02-21T17:21:21.710796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss\nplt.plot(h1.history['loss'], label='train loss')\nplt.plot(h1.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n# accuracies\nplt.plot(h1.history['accuracy'], label='train acc')\nplt.plot(h1.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-21T17:21:21.715738Z","iopub.status.idle":"2023-02-21T17:21:21.716708Z","shell.execute_reply.started":"2023-02-21T17:21:21.716461Z","shell.execute_reply":"2023-02-21T17:21:21.716484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}